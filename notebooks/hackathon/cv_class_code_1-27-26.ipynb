{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cG8BwCZsJtm"
      },
      "outputs": [],
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from google.cloud import storage\n",
        "\n",
        "# Models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torchvision.models import resnet50\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "ogvFG8nfRuFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_gcs_folder(bucket_name, gcs_folder_prefix, local_dir):\n",
        "    \"\"\"\n",
        "    Downloads all blobs from a bucket with a specific prefix.\n",
        "    \"\"\"\n",
        "    storage_client = storage.Client.create_anonymous_client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "    # The prefix filters the 'folder'\n",
        "    # Ensure it ends with a '/'\n",
        "    if not gcs_folder_prefix.endswith('/'):\n",
        "        gcs_folder_prefix += '/'\n",
        "\n",
        "    blobs = bucket.list_blobs(prefix=gcs_folder_prefix)\n",
        "\n",
        "    print(f\"Searching for files in: gs://{bucket_name}/{gcs_folder_prefix}\")\n",
        "\n",
        "    for blob in blobs:\n",
        "        # 1. Skip if the blob is just the folder placeholder itself\n",
        "        if blob.name == gcs_folder_prefix:\n",
        "            continue\n",
        "\n",
        "        # 2. Extract only the filename (remove the folder prefix)\n",
        "        # If blob.name is 'imgs_folder/IXI050.png',\n",
        "        # local_file_name becomes 'IXI050.png'\n",
        "        local_file_name = os.path.basename(blob.name)\n",
        "\n",
        "        if local_file_name: # Ensure it's not a sub-directory\n",
        "            local_path = os.path.join(local_dir, local_file_name)\n",
        "\n",
        "            # 3. Create local folder if needed\n",
        "            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
        "\n",
        "            # 4. Download\n",
        "            blob.download_to_filename(local_path)\n",
        "            print(f\"Downloaded: {local_file_name}\")"
      ],
      "metadata": {
        "id": "TFnsurPIR7Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vBKlPAEuSHFp",
        "outputId": "a0e0b5d1-02c3-485c-b57e-d1c413e2c475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_gcs_folder(\n",
        "    bucket_name='brain-age-mri-bucket',\n",
        "    gcs_folder_prefix='imgs_folder/',\n",
        "    local_dir='./data/raw'\n",
        ")"
      ],
      "metadata": {
        "id": "Ykz_hlrsSDDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a378c747-72cc-4604-8851-1c94b6af4bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for files in: gs://brain-age-mri-bucket/imgs_folder/\n",
            "Downloaded: IXI002-Guys-0828-T1.png\n",
            "Downloaded: IXI012-HH-1211-T1.png\n",
            "Downloaded: IXI013-HH-1212-T1.png\n",
            "Downloaded: IXI014-HH-1236-T1.png\n",
            "Downloaded: IXI015-HH-1258-T1.png\n",
            "Downloaded: IXI016-Guys-0697-T1.png\n",
            "Downloaded: IXI017-Guys-0698-T1.png\n",
            "Downloaded: IXI019-Guys-0702-T1.png\n",
            "Downloaded: IXI020-Guys-0700-T1.png\n",
            "Downloaded: IXI021-Guys-0703-T1.png\n",
            "Downloaded: IXI022-Guys-0701-T1.png\n",
            "Downloaded: IXI023-Guys-0699-T1.png\n",
            "Downloaded: IXI024-Guys-0705-T1.png\n",
            "Downloaded: IXI025-Guys-0852-T1.png\n",
            "Downloaded: IXI026-Guys-0696-T1.png\n",
            "Downloaded: IXI027-Guys-0710-T1.png\n",
            "Downloaded: IXI028-Guys-1038-T1.png\n",
            "Downloaded: IXI029-Guys-0829-T1.png\n",
            "Downloaded: IXI030-Guys-0708-T1.png\n",
            "Downloaded: IXI031-Guys-0797-T1.png\n",
            "Downloaded: IXI033-HH-1259-T1.png\n",
            "Downloaded: IXI034-HH-1260-T1.png\n",
            "Downloaded: IXI035-IOP-0873-T1.png\n",
            "Downloaded: IXI036-Guys-0736-T1.png\n",
            "Downloaded: IXI037-Guys-0704-T1.png\n",
            "Downloaded: IXI038-Guys-0729-T1.png\n",
            "Downloaded: IXI039-HH-1261-T1.png\n",
            "Downloaded: IXI040-Guys-0724-T1.png\n",
            "Downloaded: IXI041-Guys-0706-T1.png\n",
            "Downloaded: IXI042-Guys-0725-T1.png\n",
            "Downloaded: IXI043-Guys-0714-T1.png\n",
            "Downloaded: IXI044-Guys-0712-T1.png\n",
            "Downloaded: IXI045-Guys-0713-T1.png\n",
            "Downloaded: IXI046-Guys-0824-T1.png\n",
            "Downloaded: IXI048-HH-1326-T1.png\n",
            "Downloaded: IXI049-HH-1358-T1.png\n",
            "Downloaded: IXI050-Guys-0711-T1.png\n",
            "Downloaded: IXI051-HH-1328-T1.png\n",
            "Downloaded: IXI052-HH-1343-T1.png\n",
            "Downloaded: IXI053-Guys-0727-T1.png\n",
            "Downloaded: IXI054-Guys-0707-T1.png\n",
            "Downloaded: IXI055-Guys-0730-T1.png\n",
            "Downloaded: IXI056-HH-1327-T1.png\n",
            "Downloaded: IXI057-HH-1342-T1.png\n",
            "Downloaded: IXI058-Guys-0726-T1.png\n",
            "Downloaded: IXI059-HH-1284-T1.png\n",
            "Downloaded: IXI060-Guys-0709-T1.png\n",
            "Downloaded: IXI061-Guys-0715-T1.png\n",
            "Downloaded: IXI062-Guys-0740-T1.png\n",
            "Downloaded: IXI063-Guys-0742-T1.png\n",
            "Downloaded: IXI064-Guys-0743-T1.png\n",
            "Downloaded: IXI065-Guys-0744-T1.png\n",
            "Downloaded: IXI066-Guys-0731-T1.png\n",
            "Downloaded: IXI067-HH-1356-T1.png\n",
            "Downloaded: IXI068-Guys-0756-T1.png\n",
            "Downloaded: IXI069-Guys-0769-T1.png\n",
            "Downloaded: IXI070-Guys-0767-T1.png\n",
            "Downloaded: IXI071-Guys-0770-T1.png\n",
            "Downloaded: IXI072-HH-2324-T1.png\n",
            "Downloaded: IXI073-Guys-0755-T1.png\n",
            "Downloaded: IXI074-Guys-0771-T1.png\n",
            "Downloaded: IXI075-Guys-0754-T1.png\n",
            "Downloaded: IXI076-Guys-0753-T1.png\n",
            "Downloaded: IXI077-Guys-0752-T1.png\n",
            "Downloaded: IXI078-Guys-0751-T1.png\n",
            "Downloaded: IXI079-HH-1388-T1.png\n",
            "Downloaded: IXI080-HH-1341-T1.png\n",
            "Downloaded: IXI081-Guys-0855-T1.png\n",
            "Downloaded: IXI083-HH-1357-T1.png\n",
            "Downloaded: IXI084-Guys-0741-T1.png\n",
            "Downloaded: IXI085-Guys-0759-T1.png\n",
            "Downloaded: IXI086-Guys-0728-T1.png\n",
            "Downloaded: IXI087-Guys-0768-T1.png\n",
            "Downloaded: IXI088-Guys-0758-T1.png\n",
            "Downloaded: IXI089-Guys-0757-T1.png\n",
            "Downloaded: IXI090-Guys-0800-T1.png\n",
            "Downloaded: IXI091-Guys-0762-T1.png\n",
            "Downloaded: IXI092-HH-1436-T1.png\n",
            "Downloaded: IXI093-HH-1359-T1.png\n",
            "Downloaded: IXI094-HH-1355-T1.png\n",
            "Downloaded: IXI095-HH-1390-T1.png\n",
            "Downloaded: IXI096-HH-1391-T1.png\n",
            "Downloaded: IXI097-HH-1619-T1.png\n",
            "Downloaded: IXI098-Guys-0745-T1.png\n",
            "Downloaded: IXI099-Guys-0748-T1.png\n",
            "Downloaded: IXI100-Guys-0747-T1.png\n",
            "Downloaded: IXI101-Guys-0749-T1.png\n",
            "Downloaded: IXI102-HH-1416-T1.png\n",
            "Downloaded: IXI103-Guys-0750-T1.png\n",
            "Downloaded: IXI104-HH-1450-T1.png\n",
            "Downloaded: IXI105-HH-1471-T1.png\n",
            "Downloaded: IXI106-Guys-0760-T1.png\n",
            "Downloaded: IXI107-Guys-0761-T1.png\n",
            "Downloaded: IXI108-Guys-0865-T1.png\n",
            "Downloaded: IXI109-Guys-0732-T1.png\n",
            "Downloaded: IXI110-Guys-0733-T1.png\n",
            "Downloaded: IXI111-Guys-0734-T1.png\n",
            "Downloaded: IXI112-Guys-0735-T1.png\n",
            "Downloaded: IXI113-Guys-0776-T1.png\n",
            "Downloaded: IXI114-Guys-0737-T1.png\n",
            "Downloaded: IXI115-Guys-0738-T1.png\n",
            "Downloaded: IXI116-Guys-0739-T1.png\n",
            "Downloaded: IXI117-Guys-0763-T1.png\n",
            "Downloaded: IXI118-Guys-0764-T1.png\n",
            "Downloaded: IXI119-Guys-0765-T1.png\n",
            "Downloaded: IXI120-Guys-0766-T1.png\n",
            "Downloaded: IXI121-Guys-0772-T1.png\n",
            "Downloaded: IXI122-Guys-0773-T1.png\n",
            "Downloaded: IXI123-Guys-0774-T1.png\n",
            "Downloaded: IXI126-HH-1437-T1.png\n",
            "Downloaded: IXI127-HH-1451-T1.png\n",
            "Downloaded: IXI128-HH-1470-T1.png\n",
            "Downloaded: IXI129-Guys-0775-T1.png\n",
            "Downloaded: IXI130-HH-1528-T1.png\n",
            "Downloaded: IXI131-HH-1527-T1.png\n",
            "Downloaded: IXI132-HH-1415-T1.png\n",
            "Downloaded: IXI134-Guys-0780-T1.png\n",
            "Downloaded: IXI135-Guys-0779-T1.png\n",
            "Downloaded: IXI136-HH-1452-T1.png\n",
            "Downloaded: IXI137-HH-1472-T1.png\n",
            "Downloaded: IXI138-Guys-0746-T1.png\n",
            "Downloaded: IXI139-Guys-0815-T1.png\n",
            "Downloaded: IXI140-Guys-0787-T1.png\n",
            "Downloaded: IXI141-Guys-0789-T1.png\n",
            "Downloaded: IXI142-Guys-0786-T1.png\n",
            "Downloaded: IXI143-Guys-0785-T1.png\n",
            "Downloaded: IXI144-Guys-0788-T1.png\n",
            "Downloaded: IXI145-Guys-0781-T1.png\n",
            "Downloaded: IXI146-HH-1389-T1.png\n",
            "Downloaded: IXI148-HH-1453-T1.png\n",
            "Downloaded: IXI150-HH-1550-T1.png\n",
            "Downloaded: IXI151-Guys-0793-T1.png\n",
            "Downloaded: IXI153-Guys-0782-T1.png\n",
            "Downloaded: IXI154-Guys-0821-T1.png\n",
            "Downloaded: IXI156-Guys-0837-T1.png\n",
            "Downloaded: IXI157-Guys-0816-T1.png\n",
            "Downloaded: IXI158-Guys-0783-T1.png\n",
            "Downloaded: IXI159-HH-1549-T1.png\n",
            "Downloaded: IXI160-HH-1637-T1.png\n",
            "Downloaded: IXI161-HH-2533-T1.png\n",
            "Downloaded: IXI162-HH-1548-T1.png\n",
            "Downloaded: IXI163-HH-1621-T1.png\n",
            "Downloaded: IXI164-Guys-0844-T1.png\n",
            "Downloaded: IXI165-HH-1589-T1.png\n",
            "Downloaded: IXI166-Guys-0846-T1.png\n",
            "Downloaded: IXI167-HH-1569-T1.png\n",
            "Downloaded: IXI168-HH-1607-T1.png\n",
            "Downloaded: IXI169-Guys-0842-T1.png\n",
            "Downloaded: IXI170-Guys-0843-T1.png\n",
            "Downloaded: IXI172-Guys-0982-T1.png\n",
            "Downloaded: IXI173-HH-1590-T1.png\n",
            "Downloaded: IXI174-HH-1571-T1.png\n",
            "Downloaded: IXI175-HH-1570-T1.png\n",
            "Downloaded: IXI176-HH-1604-T1.png\n",
            "Downloaded: IXI177-Guys-0831-T1.png\n",
            "Downloaded: IXI178-Guys-0778-T1.png\n",
            "Downloaded: IXI179-Guys-0777-T1.png\n",
            "Downloaded: IXI180-HH-1605-T1.png\n",
            "Downloaded: IXI181-Guys-0790-T1.png\n",
            "Downloaded: IXI182-Guys-0792-T1.png\n",
            "Downloaded: IXI183-Guys-0791-T1.png\n",
            "Downloaded: IXI184-Guys-0794-T1.png\n",
            "Downloaded: IXI185-Guys-0795-T1.png\n",
            "Downloaded: IXI186-Guys-0796-T1.png\n",
            "Downloaded: IXI188-Guys-0798-T1.png\n",
            "Downloaded: IXI189-Guys-0799-T1.png\n",
            "Downloaded: IXI191-Guys-0801-T1.png\n",
            "Downloaded: IXI192-Guys-0878-T1.png\n",
            "Downloaded: IXI193-Guys-0810-T1.png\n",
            "Downloaded: IXI194-Guys-0818-T1.png\n",
            "Downloaded: IXI195-HH-1620-T1.png\n",
            "Downloaded: IXI196-Guys-0805-T1.png\n",
            "Downloaded: IXI197-Guys-0811-T1.png\n",
            "Downloaded: IXI198-Guys-0803-T1.png\n",
            "Downloaded: IXI199-Guys-0802-T1.png\n",
            "Downloaded: IXI200-Guys-0812-T1.png\n",
            "Downloaded: IXI201-HH-1588-T1.png\n",
            "Downloaded: IXI202-HH-1526-T1.png\n",
            "Downloaded: IXI204-HH-1651-T1.png\n",
            "Downloaded: IXI205-HH-1649-T1.png\n",
            "Downloaded: IXI206-HH-1650-T1.png\n",
            "Downloaded: IXI207-Guys-0809-T1.png\n",
            "Downloaded: IXI208-Guys-0808-T1.png\n",
            "Downloaded: IXI209-Guys-0804-T1.png\n",
            "Downloaded: IXI210-Guys-0856-T1.png\n",
            "Downloaded: IXI211-HH-1568-T1.png\n",
            "Downloaded: IXI212-HH-1643-T1.png\n",
            "Downloaded: IXI213-HH-1642-T1.png\n",
            "Downloaded: IXI214-HH-1636-T1.png\n",
            "Downloaded: IXI216-HH-1635-T1.png\n",
            "Downloaded: IXI217-HH-1638-T1.png\n",
            "Downloaded: IXI218-HH-1815-T1.png\n",
            "Downloaded: IXI219-Guys-0894-T1.png\n",
            "Downloaded: IXI221-HH-1606-T1.png\n",
            "Downloaded: IXI222-Guys-0819-T1.png\n",
            "Downloaded: IXI223-Guys-0830-T1.png\n",
            "Downloaded: IXI224-Guys-0823-T1.png\n",
            "Downloaded: IXI225-Guys-0832-T1.png\n",
            "Downloaded: IXI226-HH-1618-T1.png\n",
            "Downloaded: IXI227-Guys-0813-T1.png\n",
            "Downloaded: IXI228-Guys-0822-T1.png\n",
            "Downloaded: IXI229-Guys-0980-T1.png\n",
            "Downloaded: IXI230-IOP-0869-T1.png\n",
            "Downloaded: IXI231-IOP-0866-T1.png\n",
            "Downloaded: IXI232-IOP-0898-T1.png\n",
            "Downloaded: IXI233-IOP-0875-T1.png\n",
            "Downloaded: IXI234-IOP-0870-T1.png\n",
            "Downloaded: IXI236-Guys-0817-T1.png\n",
            "Downloaded: IXI237-Guys-1049-T1.png\n",
            "Downloaded: IXI238-IOP-0883-T1.png\n",
            "Downloaded: IXI239-HH-2296-T1.png\n",
            "Downloaded: IXI240-Guys-0834-T1.png\n",
            "Downloaded: IXI241-Guys-0833-T1.png\n",
            "Downloaded: IXI242-HH-1722-T1.png\n",
            "Downloaded: IXI244-Guys-0841-T1.png\n",
            "Downloaded: IXI246-Guys-0840-T1.png\n",
            "Downloaded: IXI247-Guys-0838-T1.png\n",
            "Downloaded: IXI248-HH-1972-T1.png\n",
            "Downloaded: IXI249-Guys-1072-T1.png\n",
            "Downloaded: IXI250-Guys-0836-T1.png\n",
            "Downloaded: IXI251-Guys-1055-T1.png\n",
            "Downloaded: IXI252-HH-1693-T1.png\n",
            "Downloaded: IXI253-HH-1694-T1.png\n",
            "Downloaded: IXI254-HH-1705-T1.png\n",
            "Downloaded: IXI255-HH-1882-T1.png\n",
            "Downloaded: IXI256-HH-1723-T1.png\n",
            "Downloaded: IXI257-HH-1724-T1.png\n",
            "Downloaded: IXI258-HH-1769-T1.png\n",
            "Downloaded: IXI259-HH-1804-T1.png\n",
            "Downloaded: IXI260-HH-1805-T1.png\n",
            "Downloaded: IXI261-HH-1704-T1.png\n",
            "Downloaded: IXI262-HH-1861-T1.png\n",
            "Downloaded: IXI263-HH-1684-T1.png\n",
            "Downloaded: IXI264-Guys-0854-T1.png\n",
            "Downloaded: IXI265-Guys-0845-T1.png\n",
            "Downloaded: IXI266-Guys-0853-T1.png\n",
            "Downloaded: IXI267-HH-1772-T1.png\n",
            "Downloaded: IXI268-Guys-0858-T1.png\n",
            "Downloaded: IXI269-Guys-0839-T1.png\n",
            "Downloaded: IXI270-Guys-0847-T1.png\n",
            "Downloaded: IXI274-HH-2294-T1.png\n",
            "Downloaded: IXI275-HH-1803-T1.png\n",
            "Downloaded: IXI276-HH-1840-T1.png\n",
            "Downloaded: IXI277-HH-1770-T1.png\n",
            "Downloaded: IXI278-HH-1771-T1.png\n",
            "Downloaded: IXI279-Guys-1044-T1.png\n",
            "Downloaded: IXI280-HH-1860-T1.png\n",
            "Downloaded: IXI282-HH-2025-T1.png\n",
            "Downloaded: IXI284-HH-2354-T1.png\n",
            "Downloaded: IXI285-Guys-0857-T1.png\n",
            "Downloaded: IXI286-Guys-0859-T1.png\n",
            "Downloaded: IXI287-Guys-0863-T1.png\n",
            "Downloaded: IXI288-Guys-0879-T1.png\n",
            "Downloaded: IXI289-Guys-0864-T1.png\n",
            "Downloaded: IXI290-IOP-0874-T1.png\n",
            "Downloaded: IXI291-IOP-0882-T1.png\n",
            "Downloaded: IXI292-IOP-0877-T1.png\n",
            "Downloaded: IXI293-IOP-0876-T1.png\n",
            "Downloaded: IXI294-IOP-0868-T1.png\n",
            "Downloaded: IXI295-HH-1814-T1.png\n",
            "Downloaded: IXI296-HH-1970-T1.png\n",
            "Downloaded: IXI297-Guys-0886-T1.png\n",
            "Downloaded: IXI298-Guys-0861-T1.png\n",
            "Downloaded: IXI299-Guys-0893-T1.png\n",
            "Downloaded: IXI300-Guys-0880-T1.png\n",
            "Downloaded: IXI302-HH-1883-T1.png\n",
            "Downloaded: IXI303-IOP-0968-T1.png\n",
            "Downloaded: IXI304-Guys-0862-T1.png\n",
            "Downloaded: IXI305-IOP-0871-T1.png\n",
            "Downloaded: IXI306-IOP-0867-T1.png\n",
            "Downloaded: IXI307-IOP-0872-T1.png\n",
            "Downloaded: IXI308-Guys-0884-T1.png\n",
            "Downloaded: IXI309-IOP-0897-T1.png\n",
            "Downloaded: IXI310-IOP-0890-T1.png\n",
            "Downloaded: IXI311-Guys-0885-T1.png\n",
            "Downloaded: IXI312-Guys-0887-T1.png\n",
            "Downloaded: IXI313-HH-2241-T1.png\n",
            "Downloaded: IXI314-IOP-0889-T1.png\n",
            "Downloaded: IXI315-IOP-0888-T1.png\n",
            "Downloaded: IXI316-HH-1862-T1.png\n",
            "Downloaded: IXI317-Guys-0896-T1.png\n",
            "Downloaded: IXI318-Guys-0895-T1.png\n",
            "Downloaded: IXI319-Guys-0901-T1.png\n",
            "Downloaded: IXI320-Guys-0902-T1.png\n",
            "Downloaded: IXI321-Guys-0903-T1.png\n",
            "Downloaded: IXI322-IOP-0891-T1.png\n",
            "Downloaded: IXI324-Guys-0922-T1.png\n",
            "Downloaded: IXI325-Guys-0911-T1.png\n",
            "Downloaded: IXI326-Guys-0907-T1.png\n",
            "Downloaded: IXI327-HH-1999-T1.png\n",
            "Downloaded: IXI328-HH-2295-T1.png\n",
            "Downloaded: IXI329-HH-1908-T1.png\n",
            "Downloaded: IXI330-Guys-0881-T1.png\n",
            "Downloaded: IXI331-IOP-0892-T1.png\n",
            "Downloaded: IXI332-IOP-1134-T1.png\n",
            "Downloaded: IXI333-IOP-0926-T1.png\n",
            "Downloaded: IXI334-HH-1907-T1.png\n",
            "Downloaded: IXI335-HH-1906-T1.png\n",
            "Downloaded: IXI336-Guys-0904-T1.png\n",
            "Downloaded: IXI337-IOP-0929-T1.png\n",
            "Downloaded: IXI338-HH-1971-T1.png\n",
            "Downloaded: IXI340-IOP-0915-T1.png\n",
            "Downloaded: IXI341-Guys-0906-T1.png\n",
            "Downloaded: IXI342-Guys-0909-T1.png\n",
            "Downloaded: IXI344-Guys-0905-T1.png\n",
            "Downloaded: IXI345-IOP-0928-T1.png\n",
            "Downloaded: IXI347-IOP-0927-T1.png\n",
            "Downloaded: IXI348-Guys-0910-T1.png\n",
            "Downloaded: IXI350-Guys-0908-T1.png\n",
            "Downloaded: IXI351-Guys-0914-T1.png\n",
            "Downloaded: IXI353-HH-1996-T1.png\n",
            "Downloaded: IXI354-HH-2024-T1.png\n",
            "Downloaded: IXI356-HH-2049-T1.png\n",
            "Downloaded: IXI357-HH-2076-T1.png\n",
            "Downloaded: IXI358-Guys-0919-T1.png\n",
            "Downloaded: IXI359-Guys-0918-T1.png\n",
            "Downloaded: IXI360-Guys-0912-T1.png\n",
            "Downloaded: IXI361-Guys-0913-T1.png\n",
            "Downloaded: IXI362-HH-2051-T1.png\n",
            "Downloaded: IXI363-HH-2050-T1.png\n",
            "Downloaded: IXI364-Guys-0920-T1.png\n",
            "Downloaded: IXI365-Guys-0923-T1.png\n",
            "Downloaded: IXI367-Guys-0917-T1.png\n",
            "Downloaded: IXI368-Guys-0916-T1.png\n",
            "Downloaded: IXI369-Guys-0924-T1.png\n",
            "Downloaded: IXI370-Guys-0921-T1.png\n",
            "Downloaded: IXI371-IOP-0970-T1.png\n",
            "Downloaded: IXI372-IOP-0971-T1.png\n",
            "Downloaded: IXI373-IOP-0967-T1.png\n",
            "Downloaded: IXI375-Guys-0925-T1.png\n",
            "Downloaded: IXI376-Guys-0938-T1.png\n",
            "Downloaded: IXI377-Guys-0937-T1.png\n",
            "Downloaded: IXI378-IOP-0972-T1.png\n",
            "Downloaded: IXI379-Guys-0943-T1.png\n",
            "Downloaded: IXI380-Guys-0944-T1.png\n",
            "Downloaded: IXI381-Guys-1024-T1.png\n",
            "Downloaded: IXI382-IOP-1135-T1.png\n",
            "Downloaded: IXI383-HH-2099-T1.png\n",
            "Downloaded: IXI384-HH-2100-T1.png\n",
            "Downloaded: IXI385-HH-2078-T1.png\n",
            "Downloaded: IXI386-HH-2077-T1.png\n",
            "Downloaded: IXI387-HH-2101-T1.png\n",
            "Downloaded: IXI388-IOP-0973-T1.png\n",
            "Downloaded: IXI389-Guys-0930-T1.png\n",
            "Downloaded: IXI390-Guys-0931-T1.png\n",
            "Downloaded: IXI391-Guys-0934-T1.png\n",
            "Downloaded: IXI392-Guys-1064-T1.png\n",
            "Downloaded: IXI393-Guys-0941-T1.png\n",
            "Downloaded: IXI394-Guys-0940-T1.png\n",
            "Downloaded: IXI395-IOP-0969-T1.png\n",
            "Downloaded: IXI396-HH-2115-T1.png\n",
            "Downloaded: IXI397-Guys-0953-T1.png\n",
            "Downloaded: IXI398-Guys-0952-T1.png\n",
            "Downloaded: IXI399-Guys-0966-T1.png\n",
            "Downloaded: IXI400-Guys-0977-T1.png\n",
            "Downloaded: IXI401-Guys-0978-T1.png\n",
            "Downloaded: IXI402-Guys-0961-T1.png\n",
            "Downloaded: IXI403-Guys-0965-T1.png\n",
            "Downloaded: IXI404-Guys-0950-T1.png\n",
            "Downloaded: IXI405-Guys-0948-T1.png\n",
            "Downloaded: IXI406-Guys-0963-T1.png\n",
            "Downloaded: IXI407-Guys-0964-T1.png\n",
            "Downloaded: IXI408-Guys-0962-T1.png\n",
            "Downloaded: IXI409-Guys-0960-T1.png\n",
            "Downloaded: IXI410-Guys-0958-T1.png\n",
            "Downloaded: IXI411-Guys-0959-T1.png\n",
            "Downloaded: IXI412-Guys-0949-T1.png\n",
            "Downloaded: IXI413-Guys-0955-T1.png\n",
            "Downloaded: IXI414-Guys-0957-T1.png\n",
            "Downloaded: IXI415-Guys-0942-T1.png\n",
            "Downloaded: IXI416-Guys-1051-T1.png\n",
            "Downloaded: IXI417-Guys-0939-T1.png\n",
            "Downloaded: IXI418-Guys-0956-T1.png\n",
            "Downloaded: IXI419-Guys-1027-T1.png\n",
            "Downloaded: IXI420-Guys-1028-T1.png\n",
            "Downloaded: IXI422-Guys-1071-T1.png\n",
            "Downloaded: IXI423-IOP-0974-T1.png\n",
            "Downloaded: IXI424-IOP-0991-T1.png\n",
            "Downloaded: IXI425-IOP-0988-T1.png\n",
            "Downloaded: IXI426-IOP-1011-T1.png\n",
            "Downloaded: IXI427-IOP-1012-T1.png\n",
            "Downloaded: IXI428-Guys-0996-T1.png\n",
            "Downloaded: IXI429-Guys-0997-T1.png\n",
            "Downloaded: IXI430-IOP-0990-T1.png\n",
            "Downloaded: IXI431-Guys-0986-T1.png\n",
            "Downloaded: IXI432-Guys-0987-T1.png\n",
            "Downloaded: IXI433-IOP-0989-T1.png\n",
            "Downloaded: IXI434-IOP-1010-T1.png\n",
            "Downloaded: IXI435-IOP-1040-T1.png\n",
            "Downloaded: IXI436-HH-2153-T1.png\n",
            "Downloaded: IXI437-HH-2152-T1.png\n",
            "Downloaded: IXI438-HH-2155-T1.png\n",
            "Downloaded: IXI439-HH-2114-T1.png\n",
            "Downloaded: IXI440-HH-2127-T1.png\n",
            "Downloaded: IXI441-HH-2154-T1.png\n",
            "Downloaded: IXI442-IOP-1041-T1.png\n",
            "Downloaded: IXI443-HH-2215-T1.png\n",
            "Downloaded: IXI444-HH-2270-T1.png\n",
            "Downloaded: IXI445-HH-2269-T1.png\n",
            "Downloaded: IXI446-HH-2325-T1.png\n",
            "Downloaded: IXI447-Guys-0979-T1.png\n",
            "Downloaded: IXI448-HH-2393-T1.png\n",
            "Downloaded: IXI449-Guys-1082-T1.png\n",
            "Downloaded: IXI450-Guys-1093-T1.png\n",
            "Downloaded: IXI451-HH-2212-T1.png\n",
            "Downloaded: IXI452-HH-2213-T1.png\n",
            "Downloaded: IXI453-HH-2214-T1.png\n",
            "Downloaded: IXI454-Guys-1083-T1.png\n",
            "Downloaded: IXI455-Guys-0981-T1.png\n",
            "Downloaded: IXI456-Guys-1019-T1.png\n",
            "Downloaded: IXI457-Guys-0984-T1.png\n",
            "Downloaded: IXI458-Guys-0993-T1.png\n",
            "Downloaded: IXI459-Guys-0992-T1.png\n",
            "Downloaded: IXI460-Guys-0999-T1.png\n",
            "Downloaded: IXI461-Guys-0998-T1.png\n",
            "Downloaded: IXI462-IOP-1042-T1.png\n",
            "Downloaded: IXI463-IOP-1043-T1.png\n",
            "Downloaded: IXI464-IOP-1029-T1.png\n",
            "Downloaded: IXI465-HH-2176-T1.png\n",
            "Downloaded: IXI467-Guys-0983-T1.png\n",
            "Downloaded: IXI468-Guys-0985-T1.png\n",
            "Downloaded: IXI469-IOP-1136-T1.png\n",
            "Downloaded: IXI470-IOP-1030-T1.png\n",
            "Downloaded: IXI473-IOP-1137-T1.png\n",
            "Downloaded: IXI474-IOP-1138-T1.png\n",
            "Downloaded: IXI475-IOP-1139-T1.png\n",
            "Downloaded: IXI476-IOP-1140-T1.png\n",
            "Downloaded: IXI477-IOP-1141-T1.png\n",
            "Downloaded: IXI478-IOP-1142-T1.png\n",
            "Downloaded: IXI479-Guys-1034-T1.png\n",
            "Downloaded: IXI480-Guys-1033-T1.png\n",
            "Downloaded: IXI481-HH-2175-T1.png\n",
            "Downloaded: IXI482-HH-2178-T1.png\n",
            "Downloaded: IXI483-HH-2177-T1.png\n",
            "Downloaded: IXI484-HH-2179-T1.png\n",
            "Downloaded: IXI485-HH-2180-T1.png\n",
            "Downloaded: IXI486-Guys-1005-T1.png\n",
            "Downloaded: IXI487-Guys-1037-T1.png\n",
            "Downloaded: IXI488-Guys-1015-T1.png\n",
            "Downloaded: IXI489-Guys-1014-T1.png\n",
            "Downloaded: IXI490-Guys-1018-T1.png\n",
            "Downloaded: IXI491-Guys-1032-T1.png\n",
            "Downloaded: IXI492-Guys-1022-T1.png\n",
            "Downloaded: IXI493-Guys-1007-T1.png\n",
            "Downloaded: IXI494-Guys-1008-T1.png\n",
            "Downloaded: IXI495-Guys-1009-T1.png\n",
            "Downloaded: IXI496-Guys-1045-T1.png\n",
            "Downloaded: IXI497-Guys-1002-T1.png\n",
            "Downloaded: IXI498-Guys-1050-T1.png\n",
            "Downloaded: IXI499-Guys-1004-T1.png\n",
            "Downloaded: IXI500-Guys-1017-T1.png\n",
            "Downloaded: IXI501-Guys-1016-T1.png\n",
            "Downloaded: IXI502-Guys-1020-T1.png\n",
            "Downloaded: IXI503-Guys-1021-T1.png\n",
            "Downloaded: IXI504-Guys-1025-T1.png\n",
            "Downloaded: IXI505-Guys-1026-T1.png\n",
            "Downloaded: IXI506-Guys-1035-T1.png\n",
            "Downloaded: IXI507-Guys-1036-T1.png\n",
            "Downloaded: IXI508-HH-2268-T1.png\n",
            "Downloaded: IXI510-IOP-1143-T1.png\n",
            "Downloaded: IXI511-HH-2238-T1.png\n",
            "Downloaded: IXI512-Guys-1054-T1.png\n",
            "Downloaded: IXI515-HH-2377-T1.png\n",
            "Downloaded: IXI516-HH-2297-T1.png\n",
            "Downloaded: IXI517-IOP-1144-T1.png\n",
            "Downloaded: IXI518-HH-2239-T1.png\n",
            "Downloaded: IXI519-HH-2240-T1.png\n",
            "Downloaded: IXI521-HH-2353-T1.png\n",
            "Downloaded: IXI522-HH-2453-T1.png\n",
            "Downloaded: IXI523-Guys-1056-T1.png\n",
            "Downloaded: IXI524-HH-2412-T1.png\n",
            "Downloaded: IXI525-HH-2413-T1.png\n",
            "Downloaded: IXI526-HH-2392-T1.png\n",
            "Downloaded: IXI527-HH-2376-T1.png\n",
            "Downloaded: IXI528-Guys-1073-T1.png\n",
            "Downloaded: IXI531-Guys-1057-T1.png\n",
            "Downloaded: IXI532-IOP-1145-T1.png\n",
            "Downloaded: IXI533-Guys-1066-T1.png\n",
            "Downloaded: IXI534-Guys-1062-T1.png\n",
            "Downloaded: IXI535-Guys-1061-T1.png\n",
            "Downloaded: IXI536-Guys-1059-T1.png\n",
            "Downloaded: IXI537-HH-2378-T1.png\n",
            "Downloaded: IXI538-HH-2411-T1.png\n",
            "Downloaded: IXI539-Guys-1067-T1.png\n",
            "Downloaded: IXI541-IOP-1146-T1.png\n",
            "Downloaded: IXI542-IOP-1147-T1.png\n",
            "Downloaded: IXI543-IOP-1148-T1.png\n",
            "Downloaded: IXI544-HH-2395-T1.png\n",
            "Downloaded: IXI546-HH-2450-T1.png\n",
            "Downloaded: IXI547-IOP-1149-T1.png\n",
            "Downloaded: IXI548-IOP-1150-T1.png\n",
            "Downloaded: IXI549-Guys-1046-T1.png\n",
            "Downloaded: IXI550-Guys-1069-T1.png\n",
            "Downloaded: IXI551-Guys-1065-T1.png\n",
            "Downloaded: IXI552-Guys-1063-T1.png\n",
            "Downloaded: IXI553-IOP-1151-T1.png\n",
            "Downloaded: IXI554-Guys-1068-T1.png\n",
            "Downloaded: IXI555-Guys-1074-T1.png\n",
            "Downloaded: IXI556-HH-2452-T1.png\n",
            "Downloaded: IXI558-Guys-1079-T1.png\n",
            "Downloaded: IXI559-HH-2394-T1.png\n",
            "Downloaded: IXI560-Guys-1070-T1.png\n",
            "Downloaded: IXI561-IOP-1152-T1.png\n",
            "Downloaded: IXI562-Guys-1131-T1.png\n",
            "Downloaded: IXI563-IOP-1153-T1.png\n",
            "Downloaded: IXI565-HH-2534-T1.png\n",
            "Downloaded: IXI566-HH-2535-T1.png\n",
            "Downloaded: IXI567-HH-2536-T1.png\n",
            "Downloaded: IXI568-HH-2607-T1.png\n",
            "Downloaded: IXI569-Guys-1101-T1.png\n",
            "Downloaded: IXI571-IOP-1154-T1.png\n",
            "Downloaded: IXI572-HH-2605-T1.png\n",
            "Downloaded: IXI573-IOP-1155-T1.png\n",
            "Downloaded: IXI574-IOP-1156-T1.png\n",
            "Downloaded: IXI575-HH-2658-T1.png\n",
            "Downloaded: IXI576-Guys-1077-T1.png\n",
            "Downloaded: IXI577-HH-2661-T1.png\n",
            "Downloaded: IXI578-Guys-1078-T1.png\n",
            "Downloaded: IXI579-Guys-1126-T1.png\n",
            "Downloaded: IXI582-Guys-1127-T1.png\n",
            "Downloaded: IXI584-Guys-1129-T1.png\n",
            "Downloaded: IXI585-Guys-1130-T1.png\n",
            "Downloaded: IXI586-HH-2451-T1.png\n",
            "Downloaded: IXI587-Guys-1128-T1.png\n",
            "Downloaded: IXI588-IOP-1158-T1.png\n",
            "Downloaded: IXI589-Guys-1080-T1.png\n",
            "Downloaded: IXI591-Guys-1084-T1.png\n",
            "Downloaded: IXI592-Guys-1085-T1.png\n",
            "Downloaded: IXI593-Guys-1109-T1.png\n",
            "Downloaded: IXI594-Guys-1089-T1.png\n",
            "Downloaded: IXI595-IOP-1159-T1.png\n",
            "Downloaded: IXI596-IOP-1160-T1.png\n",
            "Downloaded: IXI597-IOP-1161-T1.png\n",
            "Downloaded: IXI598-HH-2606-T1.png\n",
            "Downloaded: IXI599-HH-2659-T1.png\n",
            "Downloaded: IXI600-HH-2660-T1.png\n",
            "Downloaded: IXI601-HH-2700-T1.png\n",
            "Downloaded: IXI603-HH-2701-T1.png\n",
            "Downloaded: IXI605-HH-2598-T1.png\n",
            "Downloaded: IXI606-HH-2601-T1.png\n",
            "Downloaded: IXI607-Guys-1097-T1.png\n",
            "Downloaded: IXI608-HH-2599-T1.png\n",
            "Downloaded: IXI609-HH-2600-T1.png\n",
            "Downloaded: IXI610-HH-2649-T1.png\n",
            "Downloaded: IXI611-HH-2650-T1.png\n",
            "Downloaded: IXI612-HH-2688-T1.png\n",
            "Downloaded: IXI613-HH-2734-T1.png\n",
            "Downloaded: IXI614-HH-2735-T1.png\n",
            "Downloaded: IXI616-Guys-1092-T1.png\n",
            "Downloaded: IXI617-Guys-1090-T1.png\n",
            "Downloaded: IXI618-Guys-1091-T1.png\n",
            "Downloaded: IXI619-Guys-1099-T1.png\n",
            "Downloaded: IXI621-Guys-1100-T1.png\n",
            "Downloaded: IXI622-Guys-1102-T1.png\n",
            "Downloaded: IXI623-Guys-1076-T1.png\n",
            "Downloaded: IXI625-Guys-1098-T1.png\n",
            "Downloaded: IXI626-Guys-1094-T1.png\n",
            "Downloaded: IXI627-Guys-1103-T1.png\n",
            "Downloaded: IXI629-Guys-1095-T1.png\n",
            "Downloaded: IXI630-Guys-1108-T1.png\n",
            "Downloaded: IXI631-HH-2651-T1.png\n",
            "Downloaded: IXI632-HH-2652-T1.png\n",
            "Downloaded: IXI633-HH-2689-T1.png\n",
            "Downloaded: IXI634-HH-2690-T1.png\n",
            "Downloaded: IXI635-HH-2691-T1.png\n",
            "Downloaded: IXI636-HH-2733-T1.png\n",
            "Downloaded: IXI637-HH-2785-T1.png\n",
            "Downloaded: IXI638-HH-2786-T1.png\n",
            "Downloaded: IXI639-Guys-1088-T1.png\n",
            "Downloaded: IXI640-Guys-1106-T1.png\n",
            "Downloaded: IXI641-Guys-1105-T1.png\n",
            "Downloaded: IXI642-Guys-1104-T1.png\n",
            "Downloaded: IXI643-HH-2787-T1.png\n",
            "Downloaded: IXI644-Guys-1121-T1.png\n",
            "Downloaded: IXI646-HH-2653-T1.png\n",
            "Downloaded: IXI648-Guys-1107-T1.png\n",
            "Downloaded: IXI651-Guys-1118-T1.png\n",
            "Downloaded: IXI652-Guys-1116-T1.png\n",
            "Downloaded: IXI653-Guys-1122-T1.png\n",
            "Downloaded: IXI661-HH-2788-T1.png\n",
            "Downloaded: IXI662-Guys-1120-T1.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./IXI_with_filenames.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "k16KiRiKT311",
        "outputId": "20e4ac69-b08e-41e5-d751-56d4a322028c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IXI_ID  SEX_ID (1=m, 2=f)  HEIGHT  WEIGHT  ETHNIC_ID  MARITAL_ID  \\\n",
              "0       1                  1     170      80          2           3   \n",
              "1       2                  2     164      58          1           4   \n",
              "2      12                  1     175      70          1           2   \n",
              "3      13                  1     182      70          1           2   \n",
              "4      14                  2     163      65          1           4   \n",
              "\n",
              "   OCCUPATION_ID  QUALIFICATION_ID         DOB  DATE_AVAILABLE  STUDY_DATE  \\\n",
              "0              5                 2  1968-02-22               0         NaN   \n",
              "1              1                 5  1970-01-30               1  2005-11-18   \n",
              "2              1                 5  1966-08-20               1  2005-06-01   \n",
              "3              1                 5  1958-09-15               1  2005-06-01   \n",
              "4              1                 5  1971-03-15               1  2005-06-09   \n",
              "\n",
              "         AGE                file_name  \n",
              "0        NaN                      NaN  \n",
              "1  35.800137  IXI002-Guys-0828-T1.png  \n",
              "2  38.781656    IXI012-HH-1211-T1.png  \n",
              "3  46.710472    IXI013-HH-1212-T1.png  \n",
              "4  34.236824    IXI014-HH-1236-T1.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76c1a7cf-9367-4d46-809f-e28df4ba8c37\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IXI_ID</th>\n",
              "      <th>SEX_ID (1=m, 2=f)</th>\n",
              "      <th>HEIGHT</th>\n",
              "      <th>WEIGHT</th>\n",
              "      <th>ETHNIC_ID</th>\n",
              "      <th>MARITAL_ID</th>\n",
              "      <th>OCCUPATION_ID</th>\n",
              "      <th>QUALIFICATION_ID</th>\n",
              "      <th>DOB</th>\n",
              "      <th>DATE_AVAILABLE</th>\n",
              "      <th>STUDY_DATE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1968-02-22</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1970-01-30</td>\n",
              "      <td>1</td>\n",
              "      <td>2005-11-18</td>\n",
              "      <td>35.800137</td>\n",
              "      <td>IXI002-Guys-0828-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>175</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1966-08-20</td>\n",
              "      <td>1</td>\n",
              "      <td>2005-06-01</td>\n",
              "      <td>38.781656</td>\n",
              "      <td>IXI012-HH-1211-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>182</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1958-09-15</td>\n",
              "      <td>1</td>\n",
              "      <td>2005-06-01</td>\n",
              "      <td>46.710472</td>\n",
              "      <td>IXI013-HH-1212-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>163</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1971-03-15</td>\n",
              "      <td>1</td>\n",
              "      <td>2005-06-09</td>\n",
              "      <td>34.236824</td>\n",
              "      <td>IXI014-HH-1236-T1.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76c1a7cf-9367-4d46-809f-e28df4ba8c37')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76c1a7cf-9367-4d46-809f-e28df4ba8c37 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76c1a7cf-9367-4d46-809f-e28df4ba8c37');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 619,\n  \"fields\": [\n    {\n      \"column\": \"IXI_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 185,\n        \"min\": 1,\n        \"max\": 662,\n        \"num_unique_values\": 593,\n        \"samples\": [\n          42,\n          91,\n          255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SEX_ID (1=m, 2=f)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HEIGHT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 99,\n        \"min\": 0,\n        \"max\": 1850,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          169,\n          181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WEIGHT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56,\n        \"min\": 0,\n        \"max\": 960,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          90,\n          710\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ETHNIC_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MARITAL_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OCCUPATION_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"QUALIFICATION_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOB\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 567,\n        \"samples\": [\n          \"1947-03-15\",\n          \"1936-06-25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DATE_AVAILABLE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"STUDY_DATE\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2005-06-01 00:00:00\",\n        \"max\": \"2006-12-04 00:00:00\",\n        \"num_unique_values\": 185,\n        \"samples\": [\n          \"2005-07-04\",\n          \"2005-10-14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.715313488723154,\n        \"min\": 19.980835044490075,\n        \"max\": 86.3189596167009,\n        \"num_unique_values\": 543,\n        \"samples\": [\n          25.530458590006845,\n          41.94934976043805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 566,\n        \"samples\": [\n          \"IXI618-Guys-1091-T1.png\",\n          \"IXI600-HH-2660-T1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "needed_df = df[[\"IXI_ID\", \"file_name\", \"AGE\"]] # AGE is the label\n",
        "needed_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "74Uqi4U0UPJJ",
        "outputId": "239c9887-0853-40da-be80-33f742eaee4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IXI_ID                file_name        AGE\n",
              "0       1                      NaN        NaN\n",
              "1       2  IXI002-Guys-0828-T1.png  35.800137\n",
              "2      12    IXI012-HH-1211-T1.png  38.781656\n",
              "3      13    IXI013-HH-1212-T1.png  46.710472\n",
              "4      14    IXI014-HH-1236-T1.png  34.236824"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7454171-1c9f-4be4-92fc-c4395570577a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IXI_ID</th>\n",
              "      <th>file_name</th>\n",
              "      <th>AGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>IXI002-Guys-0828-T1.png</td>\n",
              "      <td>35.800137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>IXI012-HH-1211-T1.png</td>\n",
              "      <td>38.781656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>IXI013-HH-1212-T1.png</td>\n",
              "      <td>46.710472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>IXI014-HH-1236-T1.png</td>\n",
              "      <td>34.236824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7454171-1c9f-4be4-92fc-c4395570577a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e7454171-1c9f-4be4-92fc-c4395570577a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e7454171-1c9f-4be4-92fc-c4395570577a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "needed_df",
              "summary": "{\n  \"name\": \"needed_df\",\n  \"rows\": 619,\n  \"fields\": [\n    {\n      \"column\": \"IXI_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 185,\n        \"min\": 1,\n        \"max\": 662,\n        \"num_unique_values\": 593,\n        \"samples\": [\n          42,\n          91,\n          255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 566,\n        \"samples\": [\n          \"IXI618-Guys-1091-T1.png\",\n          \"IXI600-HH-2660-T1.png\",\n          \"IXI269-Guys-0839-T1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.715313488723154,\n        \"min\": 19.980835044490075,\n        \"max\": 86.3189596167009,\n        \"num_unique_values\": 543,\n        \"samples\": [\n          25.530458590006845,\n          41.94934976043805,\n          23.110198494182068\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "needed_df.dropna(subset=['file_name', 'AGE'], inplace=True)\n",
        "print(needed_df.shape)\n",
        "needed_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "ZOZiWcl5UqSe",
        "outputId": "eab3cf2c-7989-4b5f-9937-de87fbfd9c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(588, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2820119966.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  needed_df.dropna(subset=['file_name', 'AGE'], inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IXI_ID                file_name        AGE\n",
              "1       2  IXI002-Guys-0828-T1.png  35.800137\n",
              "2      12    IXI012-HH-1211-T1.png  38.781656\n",
              "3      13    IXI013-HH-1212-T1.png  46.710472\n",
              "4      14    IXI014-HH-1236-T1.png  34.236824\n",
              "5      15    IXI015-HH-1258-T1.png  24.284736"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c255753-bb30-4ee0-a106-3e34323086d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IXI_ID</th>\n",
              "      <th>file_name</th>\n",
              "      <th>AGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>IXI002-Guys-0828-T1.png</td>\n",
              "      <td>35.800137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>IXI012-HH-1211-T1.png</td>\n",
              "      <td>38.781656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>IXI013-HH-1212-T1.png</td>\n",
              "      <td>46.710472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>IXI014-HH-1236-T1.png</td>\n",
              "      <td>34.236824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>IXI015-HH-1258-T1.png</td>\n",
              "      <td>24.284736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c255753-bb30-4ee0-a106-3e34323086d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c255753-bb30-4ee0-a106-3e34323086d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c255753-bb30-4ee0-a106-3e34323086d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "needed_df",
              "summary": "{\n  \"name\": \"needed_df\",\n  \"rows\": 588,\n  \"fields\": [\n    {\n      \"column\": \"IXI_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184,\n        \"min\": 2,\n        \"max\": 662,\n        \"num_unique_values\": 563,\n        \"samples\": [\n          290,\n          599,\n          309\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 563,\n        \"samples\": [\n          \"IXI290-IOP-0874-T1.png\",\n          \"IXI599-HH-2659-T1.png\",\n          \"IXI309-IOP-0897-T1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.697722698342574,\n        \"min\": 19.980835044490075,\n        \"max\": 86.3189596167009,\n        \"num_unique_values\": 541,\n        \"samples\": [\n          61.06502395619439,\n          28.61327857631759,\n          46.29705681040383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48eb91c5"
      },
      "source": [
        "# Task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "602de354"
      },
      "source": [
        "## Prepare Data Paths\n",
        "\n",
        "### Subtask:\n",
        "Create a new column in `needed_df` with the full paths to the image files, combining the `/data/raw` directory with the 'file_name' column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dc1a523"
      },
      "source": [
        "**Reasoning**:\n",
        "To create the 'image_path' column, I will combine the directory '/data/raw' with the 'file_name' using `os.path.join` and the `apply` method on the 'file_name' column, then display the first few rows to verify.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "41baca80",
        "outputId": "7e261bc6-5ff1-42fa-9f8c-1910eb9b74ff"
      },
      "source": [
        "needed_df['image_path'] = needed_df['file_name'].apply(lambda x: os.path.join('./data/raw', x))\n",
        "needed_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1926407329.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  needed_df['image_path'] = needed_df['file_name'].apply(lambda x: os.path.join('./data/raw', x))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IXI_ID                file_name        AGE  \\\n",
              "1       2  IXI002-Guys-0828-T1.png  35.800137   \n",
              "2      12    IXI012-HH-1211-T1.png  38.781656   \n",
              "3      13    IXI013-HH-1212-T1.png  46.710472   \n",
              "4      14    IXI014-HH-1236-T1.png  34.236824   \n",
              "5      15    IXI015-HH-1258-T1.png  24.284736   \n",
              "\n",
              "                           image_path  \n",
              "1  ./data/raw/IXI002-Guys-0828-T1.png  \n",
              "2    ./data/raw/IXI012-HH-1211-T1.png  \n",
              "3    ./data/raw/IXI013-HH-1212-T1.png  \n",
              "4    ./data/raw/IXI014-HH-1236-T1.png  \n",
              "5    ./data/raw/IXI015-HH-1258-T1.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a014378f-448e-41a6-8654-d10bdc0da1bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IXI_ID</th>\n",
              "      <th>file_name</th>\n",
              "      <th>AGE</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>IXI002-Guys-0828-T1.png</td>\n",
              "      <td>35.800137</td>\n",
              "      <td>./data/raw/IXI002-Guys-0828-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>IXI012-HH-1211-T1.png</td>\n",
              "      <td>38.781656</td>\n",
              "      <td>./data/raw/IXI012-HH-1211-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>IXI013-HH-1212-T1.png</td>\n",
              "      <td>46.710472</td>\n",
              "      <td>./data/raw/IXI013-HH-1212-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>IXI014-HH-1236-T1.png</td>\n",
              "      <td>34.236824</td>\n",
              "      <td>./data/raw/IXI014-HH-1236-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>IXI015-HH-1258-T1.png</td>\n",
              "      <td>24.284736</td>\n",
              "      <td>./data/raw/IXI015-HH-1258-T1.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a014378f-448e-41a6-8654-d10bdc0da1bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a014378f-448e-41a6-8654-d10bdc0da1bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a014378f-448e-41a6-8654-d10bdc0da1bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "needed_df",
              "summary": "{\n  \"name\": \"needed_df\",\n  \"rows\": 588,\n  \"fields\": [\n    {\n      \"column\": \"IXI_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184,\n        \"min\": 2,\n        \"max\": 662,\n        \"num_unique_values\": 563,\n        \"samples\": [\n          290,\n          599,\n          309\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 563,\n        \"samples\": [\n          \"IXI290-IOP-0874-T1.png\",\n          \"IXI599-HH-2659-T1.png\",\n          \"IXI309-IOP-0897-T1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.697722698342574,\n        \"min\": 19.980835044490075,\n        \"max\": 86.3189596167009,\n        \"num_unique_values\": 541,\n        \"samples\": [\n          61.06502395619439,\n          28.61327857631759,\n          46.29705681040383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 563,\n        \"samples\": [\n          \"./data/raw/IXI290-IOP-0874-T1.png\",\n          \"./data/raw/IXI599-HH-2659-T1.png\",\n          \"./data/raw/IXI309-IOP-0897-T1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4839939e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code generated a `SettingWithCopyWarning`. To avoid this warning and ensure proper DataFrame modification, I will use `.loc` for assigning the new 'image_path' column to `needed_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "bf5b4f9c",
        "outputId": "f248764f-d56c-4cb4-b03a-d9406f265f9a"
      },
      "source": [
        "needed_df = needed_df.copy()\n",
        "needed_df['image_path'] = needed_df['file_name'].apply(lambda x: os.path.join('./data/raw', x))\n",
        "needed_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IXI_ID                file_name        AGE  \\\n",
              "1       2  IXI002-Guys-0828-T1.png  35.800137   \n",
              "2      12    IXI012-HH-1211-T1.png  38.781656   \n",
              "3      13    IXI013-HH-1212-T1.png  46.710472   \n",
              "4      14    IXI014-HH-1236-T1.png  34.236824   \n",
              "5      15    IXI015-HH-1258-T1.png  24.284736   \n",
              "\n",
              "                           image_path  \n",
              "1  ./data/raw/IXI002-Guys-0828-T1.png  \n",
              "2    ./data/raw/IXI012-HH-1211-T1.png  \n",
              "3    ./data/raw/IXI013-HH-1212-T1.png  \n",
              "4    ./data/raw/IXI014-HH-1236-T1.png  \n",
              "5    ./data/raw/IXI015-HH-1258-T1.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d04e89af-43c0-4179-a32b-5e089efe924f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IXI_ID</th>\n",
              "      <th>file_name</th>\n",
              "      <th>AGE</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>IXI002-Guys-0828-T1.png</td>\n",
              "      <td>35.800137</td>\n",
              "      <td>./data/raw/IXI002-Guys-0828-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>IXI012-HH-1211-T1.png</td>\n",
              "      <td>38.781656</td>\n",
              "      <td>./data/raw/IXI012-HH-1211-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>IXI013-HH-1212-T1.png</td>\n",
              "      <td>46.710472</td>\n",
              "      <td>./data/raw/IXI013-HH-1212-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>IXI014-HH-1236-T1.png</td>\n",
              "      <td>34.236824</td>\n",
              "      <td>./data/raw/IXI014-HH-1236-T1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>IXI015-HH-1258-T1.png</td>\n",
              "      <td>24.284736</td>\n",
              "      <td>./data/raw/IXI015-HH-1258-T1.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d04e89af-43c0-4179-a32b-5e089efe924f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d04e89af-43c0-4179-a32b-5e089efe924f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d04e89af-43c0-4179-a32b-5e089efe924f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "needed_df",
              "summary": "{\n  \"name\": \"needed_df\",\n  \"rows\": 588,\n  \"fields\": [\n    {\n      \"column\": \"IXI_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184,\n        \"min\": 2,\n        \"max\": 662,\n        \"num_unique_values\": 563,\n        \"samples\": [\n          290,\n          599,\n          309\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 563,\n        \"samples\": [\n          \"IXI290-IOP-0874-T1.png\",\n          \"IXI599-HH-2659-T1.png\",\n          \"IXI309-IOP-0897-T1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.697722698342574,\n        \"min\": 19.980835044490075,\n        \"max\": 86.3189596167009,\n        \"num_unique_values\": 541,\n        \"samples\": [\n          61.06502395619439,\n          28.61327857631759,\n          46.29705681040383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 563,\n        \"samples\": [\n          \"./data/raw/IXI290-IOP-0874-T1.png\",\n          \"./data/raw/IXI599-HH-2659-T1.png\",\n          \"./data/raw/IXI309-IOP-0897-T1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf9a464"
      },
      "source": [
        "## Split Data\n",
        "\n",
        "### Subtask:\n",
        "Split the `needed_df` into training and validation sets to prepare for model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dc65b86"
      },
      "source": [
        "**Reasoning**:\n",
        "To split the data, I will import the `train_test_split` function, define features and target variables, and then use the function to create training and validation sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52cd27e8",
        "outputId": "d1e79645-7954-463c-9a2f-42736617b2e5"
      },
      "source": [
        "X = needed_df['image_path']\n",
        "y = needed_df['AGE']\n",
        "\n",
        "# First, split into training and a combined validation/test set\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Then, split the combined validation/test set into validation and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) # 0.5 of 0.3 = 0.15 of original\n",
        "\n",
        "print(f\"Training set size: {len(X_train)} samples\")\n",
        "print(f\"Validation set size: {len(X_val)} samples\")\n",
        "print(f\"Test set size: {len(X_test)} samples\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 411 samples\n",
            "Validation set size: 88 samples\n",
            "Test set size: 89 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dbda12f"
      },
      "source": [
        "## Create PyTorch Dataset and DataLoader\n",
        "\n",
        "### Subtask:\n",
        "Define a custom PyTorch `Dataset` to handle image loading, transformations (resizing, normalization), and age label retrieval. Then, create `DataLoader` instances for both training and validation sets for efficient batch processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "663a54fb"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin creating the custom PyTorch Dataset and DataLoader, the first step is to import all the necessary libraries and modules that will be used for data handling, transformations, and batch loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c535de14",
        "outputId": "51d778a7-421a-420a-81b9-b48b3e511ce3"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "print(\"PyTorch modules imported.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch modules imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c020503"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the necessary modules are imported, I will define the custom PyTorch `Dataset` class, `MRIImageDataset`, to handle image loading, transformations, and age label retrieval. This will include the `__init__`, `__len__`, and `__getitem__` methods, as well as the image transformations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d167e772"
      },
      "source": [
        "## Load and Modify ResNet50\n",
        "\n",
        "### Subtask:\n",
        "Load the pre-trained ResNet50 model from `torchvision.models`. Modify its final fully connected layer to output a single numerical value, suitable for age regression.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04d5dbea"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin, I will import the necessary `resnet50` function from `torchvision.models` and `torch.nn` for model definition. Then, I will load the pre-trained ResNet50 model and modify its final fully connected layer for age regression, before printing the model's architecture to confirm the changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Omkar's Grid Search CV code commented out:"
      ],
      "metadata": {
        "id": "LEqIlipTz3D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.models import resnet50\n",
        "# import torch.nn as nn\n",
        "\n",
        "# def build_model():\n",
        "#     model = resnet50(pretrained=True)\n",
        "#     num_ftrs = model.fc.in_features\n",
        "#     model.fc = nn.Linear(num_ftrs, 1)\n",
        "#     return model"
      ],
      "metadata": {
        "id": "QorZfdYUydXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c536c82",
        "outputId": "59433b4e-b5eb-46b4-9662-4787637f7772"
      },
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Load a pre-trained ResNet50 model\n",
        "model = resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all parameters in the feature extractor\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. Modify the final fully connected layer for age regression\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 1)\n",
        "\n",
        "# Ensure the new final layer's parameters are trainable\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. Print the modified model architecture to verify the change\n",
        "print(\"Modified ResNet50 model architecture:\")\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified ResNet50 model architecture:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e704c08b"
      },
      "source": [
        "## Define Loss Function and Optimizer\n",
        "\n",
        "### Subtask:\n",
        "Set up the Mean Squared Error (MSE) as the loss function and an Adam optimizer to train the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b1cf70a"
      },
      "source": [
        "**Reasoning**:\n",
        "To define the loss function and optimizer, I will first determine the appropriate device (GPU or CPU) for computation, move the model to that device, and then instantiate the Mean Squared Error loss function and the Adam optimizer with a specified learning rate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### Omkar's Grid Search CV code commented out:\n",
        "\n"
      ],
      "metadata": {
        "id": "0-CkCOfpz0JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# criterion = nn.MSELoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKiJaAX8yipC",
        "outputId": "921391bf-419c-41c1-9c07-523df6c4284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae6045f7",
        "outputId": "46f58a94-e0b2-405c-91f6-15e98c9ab522"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss() # Mean Squared Error Loss for regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function (MSELoss) and Optimizer (Adam) defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loss function (MSELoss) and Optimizer (Adam) defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e912d80b"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "### Subtask:\n",
        "Implement and execute the training loop, including forward pass, loss calculation, backpropagation, and optimizer steps, over multiple epochs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7564c7f2"
      },
      "source": [
        "**Reasoning**:\n",
        "To implement the training loop as instructed, I will define the number of epochs, initialize lists for storing losses, and then write the nested loops for training and validation, including forward pass, loss calculation, backpropagation, and optimizer steps, while ensuring proper device placement and model mode settings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9e62382",
        "outputId": "090bc745-e81b-44a0-daca-1aad8554202b"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "class MRIImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, ages, transform=None):\n",
        "        self.image_paths = image_paths.to_numpy() # Convert Series to numpy array\n",
        "        self.ages = ages.to_numpy() # Convert Series to numpy array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB') # Convert to RGB to ensure 3 channels\n",
        "        age = self.ages[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(age, dtype=torch.float32)\n",
        "\n",
        "# Define transformations for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize images to 224x224 for ResNet\n",
        "    transforms.RandomHorizontalFlip(), # Optional data augmentation\n",
        "    transforms.RandomRotation(10, ), # Optional data augmentation\n",
        "    transforms.GaussianBlur(kernel_size=(5, 9)), # Optional data augmentation (patient motion)\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Optional data augmentation (scanner calibration)\n",
        "    transforms.ToTensor(), # Convert PIL Image to PyTorch Tensor (will be 3-channel for RGB)\n",
        "    AddGaussianNoise(0., 0.1), # Optional data augmentation (sensor noise / low-field scanners)\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalize for 3 channels\n",
        "])\n",
        "\n",
        "# Define transformations for validation\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalize for 3 channels\n",
        "])\n",
        "\n",
        "# Define transformations for test\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalize for 3 channels\n",
        "])\n",
        "\n",
        "print(\"MRIImageDataset class and transformations updated for RGB input, with separate transforms for validation and test sets.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRIImageDataset class and transformations updated for RGB input, with separate transforms for validation and test sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca55f0c1"
      },
      "source": [
        "**Reasoning**:\n",
        "Since the `MRIImageDataset` and the transformations have been updated to correctly handle 3-channel input, the next step is to re-create the `DataLoader` instances with these updated definitions. After that, I will re-execute the training and validation loops to apply the corrected data processing and ensure the model receives appropriate input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Omkar's Grid Search CV Trial Commented Out:"
      ],
      "metadata": {
        "id": "3QVDZ11xx40r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 32\n",
        "# num_workers = 2 # Adjust based on your system's capabilities\n",
        "\n",
        "# from torchvision.models import resnet50\n",
        "# import torch.nn as nn\n",
        "\n",
        "# def build_model():\n",
        "#     model = resnet50(pretrained=True)\n",
        "#     num_ftrs = model.fc.in_features\n",
        "#     model.fc = nn.Linear(num_ftrs, 1)\n",
        "#     return model\n",
        "\n",
        "# import copy\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import DataLoader, Subset\n",
        "# from sklearn.model_selection import KFold, ParameterGrid\n",
        "\n",
        "# import torchvision.transforms as T\n",
        "# from torchvision.transforms import InterpolationMode\n",
        "\n",
        "# # -------------------------\n",
        "# # 0) Reproducibility helpers\n",
        "# # -------------------------\n",
        "# def set_seed(seed: int = 42):\n",
        "#     import random\n",
        "#     random.seed(seed)\n",
        "#     np.random.seed(seed)\n",
        "#     torch.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# set_seed(42)\n",
        "\n",
        "# # -------------------------\n",
        "# # 1) Example custom noise transforms (tensor-level)\n",
        "# # -------------------------\n",
        "# class AddGaussianNoise:\n",
        "#     \"\"\"Assumes input is a torch tensor in [0,1] (or standardized; still works but clip might not).\"\"\"\n",
        "#     def __init__(self, sigma_range=(0.0, 0.05), p=0.5, clip=True):\n",
        "#         self.sigma_range = sigma_range\n",
        "#         self.p = p\n",
        "#         self.clip = clip\n",
        "\n",
        "#     def __call__(self, x):\n",
        "#         if torch.rand(1).item() > self.p:\n",
        "#             return x\n",
        "#         sigma = torch.empty(1).uniform_(self.sigma_range[0], self.sigma_range[1]).item()\n",
        "#         noise = torch.randn_like(x) * sigma\n",
        "#         y = x + noise\n",
        "#         if self.clip:\n",
        "#             y = torch.clamp(y, 0.0, 1.0)\n",
        "#         return y\n",
        "\n",
        "# class AddSpeckleNoise:\n",
        "#     \"\"\"x + x * N(0, sigma).\"\"\"\n",
        "#     def __init__(self, sigma_range=(0.0, 0.10), p=0.3, clip=True):\n",
        "#         self.sigma_range = sigma_range\n",
        "#         self.p = p\n",
        "#         self.clip = clip\n",
        "\n",
        "#     def __call__(self, x):\n",
        "#         if torch.rand(1).item() > self.p:\n",
        "#             return x\n",
        "#         sigma = torch.empty(1).uniform_(self.sigma_range[0], self.sigma_range[1]).item()\n",
        "#         noise = torch.randn_like(x) * sigma\n",
        "#         y = x + x * noise\n",
        "#         if self.clip:\n",
        "#             y = torch.clamp(y, 0.0, 1.0)\n",
        "#         return y\n",
        "\n",
        "# # -------------------------\n",
        "# # 2) Build transforms from a config dict\n",
        "# #    (edit to match your pipeline, e.g., Normalize / resize / grayscale handling)\n",
        "# # -------------------------\n",
        "# def make_train_transform(cfg):\n",
        "#     tfms = []\n",
        "\n",
        "#     # If your dataset already returns tensors, remove ToTensor.\n",
        "#     # If it returns PIL/numpy, keep ToTensor.\n",
        "#     # tfms.append(T.ToTensor())\n",
        "\n",
        "#     # Motion-like: blur\n",
        "#     if cfg.get(\"p_blur\", 0) > 0:\n",
        "#         tfms.append(\n",
        "#             T.RandomApply(\n",
        "#                 [T.GaussianBlur(kernel_size=cfg[\"blur_kernel\"], sigma=cfg[\"blur_sigma\"])],\n",
        "#                 p=cfg[\"p_blur\"]\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#     # Motion-like: tiny affine jitter (MRI-safe small)\n",
        "#     if cfg.get(\"p_affine\", 0) > 0:\n",
        "#         tfms.append(\n",
        "#             T.RandomApply(\n",
        "#                 [T.RandomAffine(\n",
        "#                     degrees=cfg[\"affine_degrees\"],\n",
        "#                     translate=cfg[\"affine_translate\"],\n",
        "#                     scale=cfg[\"affine_scale\"],\n",
        "#                     interpolation=InterpolationMode.BILINEAR\n",
        "#                 )],\n",
        "#                 p=cfg[\"p_affine\"]\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#     # Intensity variation (scanner calibration / hospital differences)\n",
        "#     if cfg.get(\"p_jitter\", 0) > 0:\n",
        "#         tfms.append(\n",
        "#             T.RandomApply(\n",
        "#                 [T.ColorJitter(\n",
        "#                     brightness=cfg[\"jitter_brightness\"],\n",
        "#                     contrast=cfg[\"jitter_contrast\"]\n",
        "#                 )],\n",
        "#                 p=cfg[\"p_jitter\"]\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#     # Convert to tensor if needed (uncomment if your dataset gives PIL)\n",
        "#     # tfms.append(T.ToTensor())\n",
        "\n",
        "#     # Noise should occur on tensors\n",
        "#     if cfg.get(\"p_gnoise\", 0) > 0:\n",
        "#         tfms.append(AddGaussianNoise(sigma_range=cfg[\"gnoise_sigma\"], p=cfg[\"p_gnoise\"]))\n",
        "#     if cfg.get(\"p_speckle\", 0) > 0:\n",
        "#         tfms.append(AddSpeckleNoise(sigma_range=cfg[\"speckle_sigma\"], p=cfg[\"p_speckle\"]))\n",
        "\n",
        "#     return T.Compose(tfms) if len(tfms) else None\n",
        "\n",
        "# def make_val_transform(cfg=None):\n",
        "#     # Usually no augmentation on val/test\n",
        "#     return None\n",
        "\n",
        "# # -------------------------\n",
        "# # 3) Metrics\n",
        "# # -------------------------\n",
        "# @torch.no_grad()\n",
        "# def mae_metric(preds, targets):\n",
        "#     return torch.mean(torch.abs(preds - targets)).item()\n",
        "\n",
        "# # -------------------------\n",
        "# # 4) One training epoch + one eval epoch\n",
        "# # -------------------------\n",
        "# def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "#     model.train()\n",
        "#     running = 0.0\n",
        "#     n = 0\n",
        "#     for images, ages in loader:\n",
        "#         images = images.to(device)\n",
        "#         ages = ages.to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(images).squeeze()\n",
        "#         loss = criterion(outputs, ages)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         bs = images.size(0)\n",
        "#         running += loss.item() * bs\n",
        "#         n += bs\n",
        "#     return running / max(n, 1)\n",
        "\n",
        "# @torch.no_grad()\n",
        "# def eval_one_epoch(model, loader, criterion, device):\n",
        "#     model.eval()\n",
        "#     running = 0.0\n",
        "#     n = 0\n",
        "#     all_preds = []\n",
        "#     all_targets = []\n",
        "#     for images, ages in loader:\n",
        "#         images = images.to(device)\n",
        "#         ages = ages.to(device)\n",
        "\n",
        "#         outputs = model(images).squeeze()\n",
        "#         loss = criterion(outputs, ages)\n",
        "\n",
        "#         bs = images.size(0)\n",
        "#         running += loss.item() * bs\n",
        "#         n += bs\n",
        "\n",
        "#         all_preds.append(outputs.detach().cpu())\n",
        "#         all_targets.append(ages.detach().cpu())\n",
        "\n",
        "#     val_loss = running / max(n, 1)\n",
        "#     preds = torch.cat(all_preds) if len(all_preds) else torch.tensor([])\n",
        "#     targets = torch.cat(all_targets) if len(all_targets) else torch.tensor([])\n",
        "#     val_mae = mae_metric(preds, targets) if preds.numel() else float(\"inf\")\n",
        "#     return val_loss, val_mae\n",
        "\n",
        "\n",
        "# # -------------------------\n",
        "# # 6) Grid Search with K-Fold CV\n",
        "# # -------------------------\n",
        "# def grid_search_cv(\n",
        "#     X_train, y_train,\n",
        "#     device,\n",
        "#     base_num_workers=2,\n",
        "#     n_splits=3,\n",
        "#     seed=42\n",
        "# ):\n",
        "#     # Define hyperparam grid (edit freely)\n",
        "#     param_grid = {\n",
        "#         # training hyperparams\n",
        "#         \"batch_size\": [16, 32],\n",
        "#         \"lr\": [1e-4, 3e-4],\n",
        "#         \"weight_decay\": [0.0, 1e-4],\n",
        "#         \"num_epochs\": [10, 20],\n",
        "\n",
        "#         # augment hyperparams\n",
        "#         \"p_blur\": [0.0, 0.4],\n",
        "#         \"blur_kernel\": [5],\n",
        "#         \"blur_sigma\": [(0.1, 2.0)],\n",
        "\n",
        "#         \"p_affine\": [0.0, 0.3],\n",
        "#         \"affine_degrees\": [5],\n",
        "#         \"affine_translate\": [(0.02, 0.02)],\n",
        "#         \"affine_scale\": [(0.98, 1.02)],\n",
        "\n",
        "#         \"p_jitter\": [0.0, 0.4],\n",
        "#         \"jitter_brightness\": [0.15],\n",
        "#         \"jitter_contrast\": [0.15],\n",
        "\n",
        "#         \"p_gnoise\": [0.0, 0.5],\n",
        "#         \"gnoise_sigma\": [(0.0, 0.05)],\n",
        "\n",
        "#         # optional: try speckle too, or leave at 0.0\n",
        "#         \"p_speckle\": [0.0],\n",
        "#         \"speckle_sigma\": [(0.0, 0.10)],\n",
        "#     }\n",
        "\n",
        "#     kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "#     best = {\n",
        "#         \"cfg\": None,\n",
        "#         \"mean_val_mae\": float(\"inf\"),\n",
        "#         \"fold_maes\": None,\n",
        "#     }\n",
        "\n",
        "#     all_results = []\n",
        "\n",
        "#     for cfg in ParameterGrid(param_grid):\n",
        "#         fold_maes = []\n",
        "#         fold_losses = []\n",
        "\n",
        "#         for fold, (tr_idx, va_idx) in enumerate(kf.split(X_train)):\n",
        "#             train_transform = make_train_transform(cfg)\n",
        "#             val_transform = make_val_transform(cfg)\n",
        "\n",
        "#             # Re-instantiate datasets each fold so they pick up transforms\n",
        "#             train_ds = MRIImageDataset(X_train, y_train, transform=train_transform)\n",
        "#             val_ds   = MRIImageDataset(X_train, y_train, transform=val_transform)\n",
        "\n",
        "#             train_sub = Subset(train_ds, tr_idx.tolist())\n",
        "#             val_sub   = Subset(val_ds, va_idx.tolist())\n",
        "\n",
        "#             train_loader = DataLoader(\n",
        "#                 train_sub,\n",
        "#                 batch_size=cfg[\"batch_size\"],\n",
        "#                 shuffle=True,\n",
        "#                 num_workers=base_num_workers,\n",
        "#                 pin_memory=True\n",
        "#             )\n",
        "#             val_loader = DataLoader(\n",
        "#                 val_sub,\n",
        "#                 batch_size=cfg[\"batch_size\"],\n",
        "#                 shuffle=False,\n",
        "#                 num_workers=base_num_workers,\n",
        "#                 pin_memory=True\n",
        "#             )\n",
        "\n",
        "#             # fresh model each fold\n",
        "#             model = build_model().to(device)\n",
        "\n",
        "#             optimizer = torch.optim.AdamW(\n",
        "#                 model.parameters(),\n",
        "#                 lr=cfg[\"lr\"],\n",
        "#                 weight_decay=cfg[\"weight_decay\"]\n",
        "#             )\n",
        "#             criterion = nn.MSELoss()\n",
        "\n",
        "#             # Train\n",
        "#             for epoch in range(cfg[\"num_epochs\"]):\n",
        "#                 tr_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "#                 va_loss, va_mae = eval_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "#             fold_maes.append(va_mae)\n",
        "#             fold_losses.append(va_loss)\n",
        "\n",
        "#         mean_mae = float(np.mean(fold_maes))\n",
        "#         std_mae = float(np.std(fold_maes))\n",
        "\n",
        "#         result = {\n",
        "#             \"cfg\": cfg,\n",
        "#             \"mean_val_mae\": mean_mae,\n",
        "#             \"std_val_mae\": std_mae,\n",
        "#             \"fold_maes\": fold_maes,\n",
        "#         }\n",
        "#         all_results.append(result)\n",
        "\n",
        "#         print(f\"CFG done | mean MAE={mean_mae:.3f} ({std_mae:.3f}) | {cfg}\")\n",
        "\n",
        "#         if mean_mae < best[\"mean_val_mae\"]:\n",
        "#             best = {\n",
        "#                 \"cfg\": copy.deepcopy(cfg),\n",
        "#                 \"mean_val_mae\": mean_mae,\n",
        "#                 \"fold_maes\": fold_maes,\n",
        "#             }\n",
        "\n",
        "#     # Sort results best->worst\n",
        "#     all_results.sort(key=lambda x: x[\"mean_val_mae\"])\n",
        "#     return best, all_results\n",
        "\n",
        "# # -------------------------\n",
        "# # 7) Run it\n",
        "# # -------------------------\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# best_cfg, results = grid_search_cv(\n",
        "#     X_train=X_train,\n",
        "#     y_train=y_train,\n",
        "#     device=device,\n",
        "#     base_num_workers=2,\n",
        "#     n_splits=3\n",
        "# )\n",
        "\n",
        "# print(\"\\nBEST CONFIG:\")\n",
        "# print(best_cfg[\"cfg\"])\n",
        "# print(\"BEST mean CV MAE:\", best_cfg[\"mean_val_mae\"])\n",
        "# print(\"Fold MAEs:\", best_cfg[\"fold_maes\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "Yq8lgvoCx31r",
        "outputId": "e1aa6dad-0cbd-433c-f108-db3f358a5d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 97.8M/97.8M [00:00<00:00, 226MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\", line 416, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipython-input-914292513.py\", line 23, in __getitem__\n    image = Image.open(img_path).convert('RGB') # Convert to RGB to ensure 3 channels\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3513, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/data/raw/IXI523-Guys-1056-T1.png'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3794036225.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m best_cfg, results = grid_search_cv(\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3794036225.py\u001b[0m in \u001b[0;36mgrid_search_cv\u001b[0;34m(X_train, y_train, device, base_num_workers, n_splits, seed)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0mva_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3794036225.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mrunning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\", line 416, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipython-input-914292513.py\", line 23, in __getitem__\n    image = Image.open(img_path).convert('RGB') # Convert to RGB to ensure 3 channels\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3513, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/data/raw/IXI523-Guys-1056-T1.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Omkar's Grid Search CV Trial Commented Out:"
      ],
      "metadata": {
        "id": "-hh2cbz40EZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhXrtdeMzG9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_cfg, results = grid_search_cv(X_train, y_train, device=device, ...)\n",
        "# print(best_cfg)\n",
        "\n",
        "# # Cell 33: Final train on full training set using best_cfg, then evaluate on val/test\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# # ---- 1) Unpack best hyperparams ----\n",
        "# cfg = best_cfg[\"cfg\"] if isinstance(best_cfg, dict) and \"cfg\" in best_cfg else best_cfg\n",
        "\n",
        "# batch_size   = cfg[\"batch_size\"]\n",
        "# num_epochs   = cfg[\"num_epochs\"]\n",
        "# lr           = cfg[\"lr\"]\n",
        "# weight_decay = cfg[\"weight_decay\"]\n",
        "\n",
        "# # ---- 2) Build transforms from best config ----\n",
        "# final_train_transform = make_train_transform(cfg)\n",
        "# final_val_transform   = make_val_transform(cfg)   # usually None / no aug\n",
        "# final_test_transform  = make_val_transform(cfg)   # same as val\n",
        "\n",
        "# # ---- 3) Recreate datasets/dataloaders (train on FULL X_train, y_train) ----\n",
        "# num_workers = 2  # keep your current setting\n",
        "\n",
        "# final_train_dataset = MRIImageDataset(X_train, y_train, transform=final_train_transform)\n",
        "# final_val_dataset   = MRIImageDataset(X_val, y_val, transform=final_val_transform)\n",
        "# final_test_dataset  = MRIImageDataset(X_test, y_test, transform=final_test_transform)\n",
        "\n",
        "# final_train_loader = DataLoader(final_train_dataset, batch_size=batch_size, shuffle=True,\n",
        "#                                 num_workers=num_workers, pin_memory=True)\n",
        "# final_val_loader   = DataLoader(final_val_dataset, batch_size=batch_size, shuffle=False,\n",
        "#                                 num_workers=num_workers, pin_memory=True)\n",
        "# final_test_loader  = DataLoader(final_test_dataset, batch_size=batch_size, shuffle=False,\n",
        "#                                 num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# print(f\"[FINAL] Train: {len(final_train_dataset)} | Val: {len(final_val_dataset)} | Test: {len(final_test_dataset)}\")\n",
        "# print(f\"[FINAL] batch_size={batch_size} epochs={num_epochs} lr={lr} wd={weight_decay}\")\n",
        "# print(f\"[FINAL] Using device: {device}\")\n",
        "\n",
        "# # ---- 4) Fresh model + optimizer ----\n",
        "# model = build_model().to(device)\n",
        "# criterion = nn.MSELoss()\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# # ---- 5) Train loop (tracks loss + MAE) ----\n",
        "# train_losses, val_losses, val_maes = [], [], []\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     tr_loss = train_one_epoch(model, final_train_loader, optimizer, criterion, device)\n",
        "#     va_loss, va_mae = eval_one_epoch(model, final_val_loader, criterion, device)\n",
        "\n",
        "#     train_losses.append(tr_loss)\n",
        "#     val_losses.append(va_loss)\n",
        "#     val_maes.append(va_mae)\n",
        "\n",
        "#     print(f\"[FINAL] Epoch {epoch+1}/{num_epochs} | TrainLoss={tr_loss:.4f} | ValLoss={va_loss:.4f} | ValMAE={va_mae:.3f}\")\n",
        "\n",
        "# print(\"[FINAL] Training complete.\")\n",
        "\n",
        "# # ---- 6) Evaluate on TEST (same metrics) ----\n",
        "# test_loss, test_mae = eval_one_epoch(model, final_test_loader, criterion, device)\n",
        "# print(f\"[FINAL] TEST | Loss={test_loss:.4f} | MAE={test_mae:.3f}\")\n",
        "\n",
        "# # ---- 7) (Optional) Save best model ----\n",
        "# # torch.save(model.state_dict(), \"best_model_from_gridsearch.pt\")"
      ],
      "metadata": {
        "id": "XvXC8QAJzH3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a58f510",
        "outputId": "2ca9ec5b-4288-4913-8ecf-48cb760570e1"
      },
      "source": [
        "batch_size = 32\n",
        "num_workers = 2 # Adjust based on your system's capabilities\n",
        "\n",
        "# Create dataset instances (re-instantiated to use the updated MRIImageDataset class)\n",
        "train_dataset = MRIImageDataset(X_train, y_train, transform=train_transform)\n",
        "val_dataset = MRIImageDataset(X_val, y_val, transform=val_transform)\n",
        "test_dataset = MRIImageDataset(X_test, y_test, transform=test_transform)\n",
        "\n",
        "# Create DataLoader instances (re-instantiated)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "print(f\"Training DataLoader created with {len(train_dataset)} samples and batch size {batch_size}.\")\n",
        "print(f\"Validation DataLoader created with {len(val_dataset)} samples and batch size {batch_size}.\")\n",
        "print(f\"Test DataLoader created with {len(test_dataset)} samples and batch size {batch_size}.\")\n",
        "\n",
        "# Re-execute the training\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training Phase\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for images, ages in train_loader:\n",
        "        images = images.to(device)\n",
        "        ages = ages.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs.squeeze(), ages) # .squeeze() to remove singleton dimension if present\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_train_loss = running_train_loss / len(train_dataset)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    all_val_preds = []\n",
        "    all_val_ages = []\n",
        "    with torch.no_grad():\n",
        "        for images, ages in val_loader:\n",
        "            images = images.to(device)\n",
        "            ages = ages.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs.squeeze(), ages)\n",
        "            running_val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            all_val_preds.extend(outputs.squeeze().cpu().numpy())\n",
        "            all_val_ages.extend(ages.cpu().numpy())\n",
        "\n",
        "    epoch_val_loss = running_val_loss / len(val_dataset)\n",
        "    val_losses.append(epoch_val_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataLoader created with 411 samples and batch size 32.\n",
            "Validation DataLoader created with 88 samples and batch size 32.\n",
            "Test DataLoader created with 89 samples and batch size 32.\n",
            "Epoch [1/20], Train Loss: 2270.9190, Val Loss: 991.5472\n",
            "Epoch [2/20], Train Loss: 1373.6504, Val Loss: 509.6698\n",
            "Epoch [3/20], Train Loss: 796.8543, Val Loss: 3684.2212\n",
            "Epoch [4/20], Train Loss: 497.0827, Val Loss: 8602.5515\n",
            "Epoch [5/20], Train Loss: 358.8608, Val Loss: 12471.5030\n",
            "Epoch [6/20], Train Loss: 310.4853, Val Loss: 15605.7100\n",
            "Epoch [7/20], Train Loss: 291.3559, Val Loss: 17077.6479\n",
            "Epoch [8/20], Train Loss: 302.5663, Val Loss: 17733.8624\n",
            "Epoch [9/20], Train Loss: 292.5067, Val Loss: 17957.1479\n",
            "Epoch [10/20], Train Loss: 293.7130, Val Loss: 17512.6042\n",
            "Epoch [11/20], Train Loss: 285.9221, Val Loss: 16672.1612\n",
            "Epoch [12/20], Train Loss: 287.4324, Val Loss: 17297.4038\n",
            "Epoch [13/20], Train Loss: 285.4357, Val Loss: 16649.8779\n",
            "Epoch [14/20], Train Loss: 290.1644, Val Loss: 17217.9798\n",
            "Epoch [15/20], Train Loss: 297.4311, Val Loss: 16617.8187\n",
            "Epoch [16/20], Train Loss: 286.7476, Val Loss: 17397.0982\n",
            "Epoch [17/20], Train Loss: 294.8308, Val Loss: 16519.4679\n",
            "Epoch [18/20], Train Loss: 284.0723, Val Loss: 16464.2312\n",
            "Epoch [19/20], Train Loss: 291.2173, Val Loss: 17516.0069\n",
            "Epoch [20/20], Train Loss: 286.9575, Val Loss: 16668.5509\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ff76c3c"
      },
      "source": [
        "## Evaluate Model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model on the validation set and report key regression metrics such as Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a02eb86"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the model, I will import the necessary metrics from `sklearn.metrics` and then calculate and print the Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) using the collected validation predictions and actual ages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e89b5f1",
        "outputId": "2d98b3c1-c022-4482-9fb1-b6d38f524a0d"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(all_val_ages, all_val_preds)\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(all_val_ages, all_val_preds)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 127.1237\n",
            "Root Mean Squared Error (RMSE): 129.1067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be43992c"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the model's performance and discuss any initial insights gained from the age prediction task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f68c163"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "*   **Model's performance:** The model achieved a Mean Absolute Error (MAE) of 7.1816 and a Root Mean Squared Error (RMSE) of 9.0908 on the validation set for age prediction.\n",
        "*   **Initial insights gained:**\n",
        "    *   The model can learn to predict age from MRI images, albeit with a notable error margin. An MAE of around 7 years suggests predictions are typically off by about 7 years.\n",
        "    *   Careful handling of data transformations, especially channel consistency (converting grayscale MRI images to a 3-channel format expected by pre-trained models like ResNet50), is crucial for successful deep learning image tasks.\n",
        "    *   The `SettingWithCopyWarning` was successfully mitigated by explicitly copying the DataFrame before modification.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Data Path Preparation:** A new `image_path` column was successfully added to the DataFrame, providing full file paths for image loading. The `SettingWithCopyWarning` was resolved by explicitly copying the DataFrame.\n",
        "*   **Data Splitting:** The dataset was split into a training set of 470 samples and a validation set of 118 samples, with 80% for training and 20% for validation.\n",
        "*   **Custom Dataset and DataLoader:** A custom `MRIImageDataset` was created to handle image loading, transformations, and age label retrieval. `DataLoader` instances were successfully created for both training (470 samples) and validation (118 samples) with a batch size of 32.\n",
        "*   **Model Architecture:** A pre-trained ResNet50 model was loaded, and its final fully connected layer was successfully modified to output a single value for age regression.\n",
        "*   **Image Channel Handling:** To ensure compatibility with the 3-channel input expectation of ResNet50, a custom `GrayscaleToRGBTensor` transformation was implemented. This allowed 1-channel grayscale MRI images to be correctly processed by the model by replicating the single channel three times.\n",
        "*   **Loss Function and Optimizer:** Mean Squared Error (MSE) was set as the loss function for regression, and the Adam optimizer with a learning rate of 0.001 was chosen for model training.\n",
        "*   **Model Training:** The model was successfully trained for 20 epochs. The training process encountered and resolved an initial channel mismatch error by incorporating the custom 3-channel conversion into the data transformation pipeline.\n",
        "*   **Model Evaluation:** On the validation set, the model achieved a Mean Absolute Error (MAE) of 7.1816 and a Root Mean Squared Error (RMSE) of 9.0908.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current MAE of ~7 years suggests room for improvement. Further optimization could include hyperparameter tuning (learning rate, batch size, optimizer), experimenting with different data augmentations, or exploring more complex model architectures (e.g., deeper networks or specialized MRI models).\n",
        "*   Consider performing error analysis on the validation set predictions to understand if the model consistently mispredicts certain age groups or image characteristics, which could guide further data preprocessing or model refinement.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}